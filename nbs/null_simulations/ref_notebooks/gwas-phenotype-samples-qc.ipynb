{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample QC for GWAS analysis\n",
    "\n",
    "## As-Is Software Disclaimer\n",
    "\n",
    "This notebook is delivered \"As-Is\". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n",
    "\n",
    "[MIT License](https://github.com/dnanexus/UKB_RAP/blob/main/LICENSE) applies to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyterlab app details (launch configuration)\n",
    "\n",
    "Recommended configuration\n",
    "- Runtime: ~5 min\n",
    "- Cluster configuration: `Single Node`\n",
    "- Recommended instance: `mem1_ssd1_v2_x36`\n",
    "- Cost: ~£0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "|Library |License|\n",
    "|:------------- |:-------------|\n",
    "|[pandas](https://pandas.pydata.org/) |[BSD-3](https://github.com/pandas-dev/pandas/blob/main/LICENSE)|\n",
    "|[numpy](https://numpy.org/) |[BSD-3](https://github.com/numpy/numpy/blob/main/LICENSE.txt)|\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook:\n",
    "- Loads cohorts created in cohort browser\n",
    "- Performs sample QC\n",
    "- Creates a file containing phenotype and covariate information needed for GWAS analysis\n",
    "\n",
    "Data used for this notebook:\n",
    "- Cohorts (`ischemia_cases` `ischemia_controls`) created using Cohort Browser\n",
    "- Dataset to retrieve phenotype data for both cohorts (`ischemia.pheno`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# dxpy allows python to interact with the platform storage\n",
    "import dxpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_folder = 'Imputation from genotype (GEL)'\n",
    "imputation_field_id = '21008'\n",
    "output_dir = '/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset description containing phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically discover dispensed dataset ID\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename='Dataset', name='app*.dataset', folder='/', name_mode='glob'\n",
    ")\n",
    "dispensed_dataset_id = dispensed_dataset['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project ID\n",
    "project_id = dxpy.find_one_project()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (':').join([project_id, dispensed_dataset_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `-ddd` parameter will extract 3 dictionary files associated with the dataset.\n",
    "\n",
    "The 3 dictionary files that are returned include:\n",
    "1. `entity_dictionary` that contains the different tables resources that are available. The table we’re most interested in tends to be the participant table that contains the information about each participant.\n",
    "2. `data_dictionary` that contains the different field names that we might want to include in our dataset.\n",
    "3. `coding_dictionary` that contains a lookup for the values for some of the field names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\n",
    "cmd = ['dx', 'extract_dataset', dataset, '-ddd', '--delimiter', ',']\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cohorts that were created in cohort browser\n",
    "\n",
    "Cohorts were created in Cohort Browser. `ischemic_cases` cohort was created by having the following condition in the field [41270](https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=41270) condition `I20-I25 Ischaemic heart disease`. `ischemic_controls` was created by using Cohorts compare: not in `ischemic_cases`.\n",
    "\n",
    "Here we use the `load_cohort` function from dxdata to load the cohort record. For more information about dxdata, see the associated [github repository](https://github.com/dnanexus/OpenBio/blob/master/dxdata/getting_started_with_dxdata.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover cohort data\n",
    "dispensed_control_id = list(\n",
    "    dxpy.find_data_objects(\n",
    "        typename='CohortBrowser',\n",
    "        folder='/Cohorts',\n",
    "        name_mode='exact',\n",
    "        name='ischemic_controls',\n",
    "    )\n",
    ")[0]['id']\n",
    "\n",
    "dispensed_case_id = list(\n",
    "    dxpy.find_data_objects(\n",
    "        typename='CohortBrowser',\n",
    "        folder='/Cohorts',\n",
    "        name_mode='exact',\n",
    "        name='ischemic_cases',\n",
    "    )\n",
    ")[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dataset = (':').join([project_id, dispensed_control_id])\n",
    "case_dataset = (':').join([project_id, dispensed_case_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve phenotypic data\n",
    "\n",
    "Specify fields ID to retrieve, get corresponding UKB RAP field names and print description table.\n",
    "\n",
    "- `31` - [Sex](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=31)\n",
    "- `2966` - [Age high blood pressure diagnosed](https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=2966)\n",
    "- `22001` - [Genetic sex](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=22001)\n",
    "- `22006` - [Genetic ethnic grouping](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=22006)\n",
    "- `22019` - [Sex chromosome aneuploidy](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=22019)\n",
    "- `22021` - [Genetic kinship to other participants](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=22021)\n",
    "- `21022` - [Age at recruitment](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=21022)\n",
    "- `23104` - [Body mass index (BMI)](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=23104)\n",
    "- `20160` - [Ever smoked](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=20160)\n",
    "- `30760` - [HDL cholesterol](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=30760)\n",
    "- `30780` - [LDL direct](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=30780)\n",
    "- `22020` - [Used in genetic principal components](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=22020)\n",
    "- `22009` - [Genetic principal components](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=22009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ids = [\n",
    "    '31',\n",
    "    '2966',\n",
    "    '22001',\n",
    "    '22006',\n",
    "    '22019',\n",
    "    '22021',\n",
    "    '21022',\n",
    "    '23104',\n",
    "    '20160',\n",
    "    '30760',\n",
    "    '30780',\n",
    "    '22020',\n",
    "    '22009'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_csv = glob.glob(os.path.join(path, '*.data_dictionary.csv'))[0]\n",
    "data_dict_df = pd.read_csv(data_dict_csv)\n",
    "data_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UKB participant tables have the following naming convention for the fields (or columns): `p<field id>_i<instance id>_a<array id>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_for_id(field_id):\n",
    "    '''Collect all field names (e.g. 'p<field_id>_iYYY_aZZZ') given a list of field IDs and return string to pass into extract_dataset'''\n",
    "    field_names = ['eid']\n",
    "    for _id in field_id:\n",
    "        select_field_names = list(\n",
    "            data_dict_df[\n",
    "                data_dict_df.name.str.match(r'^p{}(_i\\d+)?(_a\\d+)?$'.format(_id))\n",
    "            ].name.values\n",
    "        )\n",
    "        # Note: This conditional is used to select only the first instance for all fields except '2966'\n",
    "        # This conditional is not needed otherwise\n",
    "        # For PCA field, select the first ten PCs\n",
    "        if _id == '22009':\n",
    "            field_names += select_field_names[:10]\n",
    "        # Select only the first instance for all fields except '2966' \n",
    "        elif _id != '2966' and len(select_field_names) > 1:\n",
    "            field_names.append(select_field_names[0])\n",
    "        else:\n",
    "            field_names += select_field_names\n",
    "\n",
    "    field_names = [f'participant.{f}' for f in field_names]\n",
    "    return ','.join(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = fields_for_id(field_ids)\n",
    "field_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select phenotypes for case and control cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\n",
    "# Note: There is no space separating the different fields\n",
    "cmd = [\n",
    "    'dx',\n",
    "    'extract_dataset',\n",
    "    control_dataset,\n",
    "    '--fields',\n",
    "    field_names,\n",
    "    '--delimiter',\n",
    "    ',',\n",
    "    '--output',\n",
    "    'control_dictionary.csv',\n",
    "]\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    'dx',\n",
    "    'extract_dataset',\n",
    "    case_dataset,\n",
    "    '--fields',\n",
    "    field_names,\n",
    "    '--delimiter',\n",
    "    ',',\n",
    "    '--output',\n",
    "    'case_dictionary.csv',\n",
    "]\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dict_csv = 'control_dictionary.csv'\n",
    "control_df = pd.read_csv(control_dict_csv)\n",
    "print(control_df.shape)\n",
    "control_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers\n",
    "control_df = control_df.rename(columns=lambda x: re.sub('participant.', '', x))\n",
    "control_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_dict_csv = 'case_dictionary.csv'\n",
    "case_df = pd.read_csv(case_dict_csv)\n",
    "print(case_df.shape)\n",
    "case_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df = case_df.rename(columns=lambda x: re.sub('participant.', '', x))\n",
    "case_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create phenotype variable and concatenate cohorts into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df['ischemia_cc'] = 1\n",
    "control_df['ischemia_cc'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([case_df, control_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The counts should be consistent with the counts from the Cohort Browser\n",
    "df.ischemia_cc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of retrieved data.\n",
    "\n",
    "*Note: this table contains synthetic data and is made for demonstration purposes only!*\n",
    "\n",
    "|Row|eid|p31|p2966_i0|p2966_i1|p2966_i2|p2966_i3|p22001|p22006|p22019|p22021|p22022|p23104_i0|p20160_i0|p30760_i0|p30780_i0|p22020|ischemia_cc|\n",
    "|:---|:--- |:---|:--- |:---|:---|:---|:---|:--- |:---|:---|:--- |:---|:--- |:---|:--- |:---|:---|\n",
    "|0 |EID-XXXXXXX|0 |58.0|NA|NA|NA|0.0|1.0|NA|0.0|61.0|28.5|1.0|0.959|2.456|1.0|1|\n",
    "|1 |EID-YYYYYYY|1 |NA  |NA|NA|NA|1.0|1.0|NA|0.0|51.0|24.5|1.0|1.159|2.719|1.0|1|\n",
    "|2 |EID-ZZZZZZZ|1 |50.0|NA|NA|NA|1.0|1.0|NA|1.0|64.0|29.7|1.0|0.970|3.440|NA |1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC samples based on several conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced = df[\n",
    "    (df['p31'] == df['p22001']) # Filter reported sex and genetic sex are the same\n",
    "    & (df['p22006'] == 1)  # Only include Caucasian ancestry (In_white_british_ancestry_subset)\n",
    "    & (  \n",
    "        df['p22019'].isnull() # No Sex chromosome aneuploidy\n",
    "    )\n",
    "    & (  \n",
    "        df['p22020'] == 1 # Participant was used to calculate PCA (only non-relatives were included)\n",
    "    )  \n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced.ischemia_cc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare covariates for subsequent regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all instances of `Age high blood pressure diagnosed` (`2966`) field and make `hypertension` boolean variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced['hypertension'] = [\n",
    "    np.nansum([float(row[i]) for i in [0, 1, 2, 3]]) > 0\n",
    "    for row in df_qced[['p2966_i0', 'p2966_i1', 'p2966_i2', 'p2966_i3']].to_numpy()\n",
    "]\n",
    "df_qced['hypertension'] = df_qced['hypertension'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `Ever smoked` (`20160`) make all missing values as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced['p20160_i0'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of covariate columns, replace missing values by mean for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced['p23104_i0'].fillna(df_qced['p23104_i0'].mean(), inplace=True)\n",
    "df_qced['p30760_i0'].fillna(df_qced['p30760_i0'].mean(), inplace=True)\n",
    "df_qced['p30780_i0'].fillna(df_qced['p30780_i0'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns and organize it in format suitable for PLINK and regenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for better readibility\n",
    "df_qced = df_qced.rename(columns=lambda x: re.sub('p22009_a','pc',x))\n",
    "df_qced = df_qced.rename(\n",
    "    columns={\n",
    "        'eid': 'IID',\n",
    "        'p31': 'sex',\n",
    "        'p21022': 'age',\n",
    "        'p20160_i0': 'ever_smoked',\n",
    "        'p23104_i0': 'bmi',\n",
    "        'p30760_i0': 'hdl_cholesterol',\n",
    "        'p30780_i0': 'ldl_cholesterol',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add FID column -- required input format for regenie\n",
    "df_qced['FID'] = df_qced['IID']\n",
    "\n",
    "# Create a phenotype table from our QCed data\n",
    "cols = [\n",
    "        'FID',\n",
    "        'IID',\n",
    "        'sex',\n",
    "        'age',\n",
    "        'bmi',\n",
    "        'ever_smoked',\n",
    "        'hdl_cholesterol',\n",
    "        'ldl_cholesterol',\n",
    "        'hypertension',\n",
    "        'ischemia_cc',\n",
    "]\n",
    "cols.extend([col for col in df_qced if 'pc' in col])\n",
    "df_phenotype = df_qced[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotype.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only samples that have imputed data available and save phenotype table as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get imputed data\n",
    "path_to_impute_file = f'/mnt/project/Bulk/Imputation/{imputation_folder}/ukb{imputation_field_id}_c1_b0_v1.sample'\n",
    "sample_file = pd.read_csv(\n",
    "    path_to_impute_file,\n",
    "    delimiter='\\s',\n",
    "    header=0,\n",
    "    names=['FID', 'IID', 'missing', 'sex'],\n",
    "    engine='python',\n",
    ")\n",
    "# Intersect the phenotype file and the imputed .sample file\n",
    "# to generate phenotype DataFrame for only samples included in the imputed data\n",
    "ischemia_df = df_phenotype.join(\n",
    "    sample_file.set_index('IID'), on='IID', rsuffix='_sample', how='inner'\n",
    ")\n",
    "# Drop unuseful columns from .fam file\n",
    "ischemia_df.drop(\n",
    "    columns=['FID_sample', 'missing', 'sex_sample'],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    "    errors='ignore',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write phenotype files to a TSV file\n",
    "ischemia_df.to_csv('ischemia_df.phe', sep='\\t', na_rep='NA', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ischemia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file to project storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$output_dir\"\n",
    "# Upload the geno-pheno intersect phenotype file back to the RAP project\n",
    "dx upload ischemia_df.phe -p --path $1 --brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of phenotype file.\n",
    "\n",
    "*Note: this table contains synthetic data and is made for demonstration purposes only!*\n",
    "\n",
    "|Row|FID|IID|sex|age|bmi|ever_smoked|hypertension|hdl_cholesterol|ldl_cholesterol|ischemia_cc|\n",
    "|:--- |:--- |:---|:--- |:---|:---|:---|:---|:--- |:---|:---|\n",
    "|0|EID-XXXXXXX|1234567|0|61.0|28.5|0|1|0.959|2.456|1|1|1|\n",
    "|1|EID-YYYYYYY|1234568|1|51.0|24.5|0|0|1.159|2.719|0|1|1|\n",
    "|2|EID-ZZZZZZZ|1234569|0|60.0|23.8|1|1|1.579|3.396|0|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output files\n",
    "\n",
    "- Table containing phenotype and covariates to be used in regenie GWAS analysis (`ischemia_df.phe`)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
